{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Tree Credit Risk\n",
    "\n",
    "### Dependencies and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import EasyEnsembleClassifier, BalancedRandomForestClassifier\n",
    "\n",
    "# print(mpl.style.available)\n",
    "mpl.style.use('Solarize_Light2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect top rows in data\n",
    "with open(Path('data/loans_1q19.csv')) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df = pd.read_csv(Path('data/loans_1q19.csv'), skiprows=1, low_memory=False)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unusable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows and columns with more than 10% its values missing\n",
    "df.dropna(axis=1, thresh=df.shape[0]*0.9, inplace=True) # drop cols\n",
    "df.dropna(axis=0, thresh=df.shape[1]*0.9, inplace=True) # drop rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant columns\n",
    "const_cols = df.nunique()[df.nunique() < 2].index # cols w/ 1 unique val\n",
    "df.drop(const_cols, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop newly issued loans\n",
    "df = df[df['loan_status'] != 'Issued']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect non-numeric columns\n",
    "df_num = df.copy() # make a copy\n",
    "obj_cols = df_num.dtypes[df_num.dtypes == object].index\n",
    "df[obj_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" String manipulation \"\"\"\n",
    "\n",
    "# Convert `term` to numeric\n",
    "df_num['term'] = df['term'].str.replace(' months', '').astype(float)\n",
    "\n",
    "# Convert `int_rate` to numeric\n",
    "df_num['int_rate'] = df['int_rate'].str.replace('%', '').astype(float)\n",
    "\n",
    "# Convert `emp_length` to numeric\n",
    "df_num['emp_length'] = df['emp_length'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Convert `revol_util` to numeric\n",
    "df_num['revol_util'] = df['revol_util'].str.replace('%', '').astype(float)\n",
    "\n",
    "df_num[obj_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Datetime manipulation \"\"\"\n",
    "\n",
    "# Create a new column for `issue_d` as numeric type\n",
    "df_num['issue_month'] = pd.to_datetime(df['issue_d']).dt.month\n",
    "\n",
    "# Create a new column for `earliest_cr_line` as numeric type\n",
    "df_num['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line']) # convert to dt\n",
    "youngest_cr = df_num['earliest_cr_line'].max() # latest date in data\n",
    "df_num['oldest_cr_age'] = (youngest_cr - df_num['earliest_cr_line']).dt.days # oldest credit age\n",
    "\n",
    "# Create a new column for 'last_credit_pull_d' as numeric type\n",
    "df_num['last_credit_pull_month'] = pd.to_datetime(df['last_credit_pull_d']).dt.month\n",
    "df_num['last_credit_pull_month'] = df_num['last_credit_pull_month'].replace(12, 0) # set Dec 2018 as month 0\n",
    "\n",
    "df_num[obj_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Numeric mapping \"\"\"\n",
    "\n",
    "# Convert `grade` to numeric\n",
    "grade_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7} # num mapping\n",
    "df_num['grade'] = df['grade'].map(grade_mapping).astype(float)\n",
    "\n",
    "# Convert `home_ownership` to numeric\n",
    "home_mapping = dict.fromkeys(['RENT', 'ANY', 'NONE'], 0) # num mapping\n",
    "home_mapping.update(dict.fromkeys(['MORTGAGE', 'OWN'], 1)) # add 1 label\n",
    "df_num['home_ownership'] = df['home_ownership'].map(home_mapping).astype(float)\n",
    "\n",
    "# Convert `verification_state` to numeric\n",
    "df_num['verification_status'] = df['verification_status'].str.replace('Source ', '') # combine verified labels\n",
    "veri_mapping = {'Not Verified': 0, 'Verified': 1} # num mapping\n",
    "df_num['verification_status'] = df['verification_status'].map(veri_mapping).astype(float)\n",
    "\n",
    "# Create a new column for `initial_list_status` as numeric type\n",
    "init_mapping = {'f': 0, 'w': 1} # num mapping\n",
    "df_num['whole_loan'] = df['initial_list_status'].map(init_mapping).astype(float)\n",
    "\n",
    "# Create a new column for `application_type` as numeric type\n",
    "app_mapping = {'Individual': 0, 'Joint App': 1} # num mapping\n",
    "df_num['joint_app'] = df['application_type'].map(app_mapping).astype(float)\n",
    "\n",
    "# Create a new column for `loan_status` as numeric type\n",
    "stat_mapping = dict.fromkeys(['Charged Off', 'In Grace Period', # num mapping\n",
    "                              'Late (16-30 days)', 'Late (31-120 days)'], 1) # high risk\n",
    "stat_mapping.update(dict.fromkeys(['Fully Paid', 'Current'], 0)) # low risk\n",
    "df_num['high_risk'] = df['loan_status'].map(stat_mapping).astype(float)\n",
    "\n",
    "df_num[obj_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" One-hot encoding \"\"\"\n",
    "\n",
    "# Group labels into 3 categories\n",
    "df_num['purpose'] = df['purpose'].replace(['debt_consolidation', 'credit_card', 'medical'], 'debt') \\\n",
    "                                 .replace(['home_improvement', 'car', 'house', 'vacation'], 'major_purchase') \\\n",
    "                                 .replace(['small_business', 'moving', 'renewable_energy', 'other'], '_other')\n",
    "\n",
    "# One-hot encode `purpose` and drop the last label\n",
    "df_num = pd.get_dummies(df_num, columns=['purpose'], drop_first=True)\n",
    "df_num.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant cols\n",
    "cols_to_drop = ['title', 'sub_grade', 'zip_code', 'issue_d', 'loan_status', \n",
    "                'earliest_cr_line', 'addr_state', 'verification_status', 'next_pymnt_d', \n",
    "                'last_credit_pull_d', 'initial_list_status', 'application_type']\n",
    "df_num.drop(cols_to_drop, axis=1, inplace=True)\n",
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_num.dropna(inplace=True)\n",
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated columns\n",
    "cor_cols = []\n",
    "for i in range(df_num.shape[1] - 1):\n",
    "    for j in range(i + 1, df_num.shape[1]):\n",
    "        col1 = df_num.iloc[:, i]\n",
    "        col2 = df_num.iloc[:, j]\n",
    "        cor = col1.corr(col2)\n",
    "        if abs(cor) > 0.7:\n",
    "            print(col1.name, col2.name, cor)\n",
    "            if col2.name not in cor_cols:\n",
    "                cor_cols.append(col2.name)\n",
    "                \n",
    "cor_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated columns, keeping only 1 column per correlation\n",
    "df_num.drop(cor_cols, axis=1, inplace=True)\n",
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find integer columns\n",
    "df_int = df_num % 1\n",
    "int_cols = df_int.nunique()[df_int.nunique() < 2].index\n",
    "\n",
    "# Convert above columns to integer type\n",
    "for col in int_cols:\n",
    "    df_num[col] = df_num[col].astype(int)\n",
    "    \n",
    "df_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df_num.reset_index(drop=True, inplace=True)\n",
    "df_num.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count target labels\n",
    "df_num['high_risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature/target split\n",
    "X = df_num.drop('high_risk', axis=1).copy()\n",
    "y = df_num['high_risk'].copy()\n",
    "\n",
    "# Train/validation/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count target labels in each set\n",
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "# X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "# X_train_scaled.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "lr_val_pred = lr.predict(X_val)\n",
    "print(classification_report(y_val, lr_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "tree_val_pred = tree.predict(X_val)\n",
    "print(classification_report(y_val, tree_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "Counter(y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_rus = LogisticRegression(random_state=42)\n",
    "lr_rus.fit(X_rus, y_rus)\n",
    "\n",
    "# Evaluate model\n",
    "lr_rus_val_pred = lr_rus.predict(X_val)\n",
    "print(classification_report(y_val, lr_rus_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_rus_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_rus_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree_rus = DecisionTreeClassifier(random_state=42)\n",
    "tree_rus.fit(X_rus, y_rus)\n",
    "\n",
    "# Evaluate model\n",
    "tree_rus_val_pred = tree_rus.predict(X_val)\n",
    "print(classification_report(y_val, tree_rus_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_rus_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_rus_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centroid undersampling\n",
    "ccu = ClusterCentroids(random_state=42)\n",
    "X_ccu, y_ccu = ccu.fit_resample(X_train, y_train)\n",
    "Counter(y_ccu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_ccu = LogisticRegression(random_state=42)\n",
    "lr_ccu.fit(X_ccu, y_ccu)\n",
    "\n",
    "# Evaluate model\n",
    "lr_ccu_val_pred = lr_ccu.predict(X_val)\n",
    "print(classification_report(y_val, lr_ccu_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_ccu_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_ccu_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree_ccu = DecisionTreeClassifier(random_state=42)\n",
    "tree_ccu.fit(X_ccu, y_ccu)\n",
    "\n",
    "# Evaluate model\n",
    "tree_ccu_val_pred = tree_ccu.predict(X_val)\n",
    "print(classification_report(y_val, tree_ccu_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_ccu_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_ccu_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_ros = LogisticRegression(random_state=42)\n",
    "lr_ros.fit(X_ros, y_ros)\n",
    "\n",
    "# Evaluate model\n",
    "lr_ros_val_pred = lr_ros.predict(X_val)\n",
    "print(classification_report(y_val, lr_ros_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_ros_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_ros_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree_ros = DecisionTreeClassifier(random_state=42)\n",
    "tree_ros.fit(X_ros, y_ros)\n",
    "\n",
    "# Evaluate model\n",
    "tree_ros_val_pred = tree_ros.predict(X_val)\n",
    "print(classification_report(y_val, tree_ros_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_ros_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_ros_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "smo = SMOTE(random_state=42)\n",
    "X_smo, y_smo = smo.fit_resample(X_train, y_train)\n",
    "Counter(y_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_smo = LogisticRegression(random_state=42)\n",
    "lr_smo.fit(X_smo, y_smo)\n",
    "\n",
    "# Evaluate model\n",
    "lr_smo_val_pred = lr_smo.predict(X_val)\n",
    "print(classification_report(y_val, lr_smo_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_smo_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_smo_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree_smo = DecisionTreeClassifier(random_state=42)\n",
    "tree_smo.fit(X_smo, y_smo)\n",
    "\n",
    "# Evaluate model\n",
    "tree_smo_val_pred = tree_smo.predict(X_val)\n",
    "print(classification_report(y_val, tree_smo_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_smo_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_smo_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN\n",
    "sen = SMOTEENN(random_state=42)\n",
    "X_sen, y_sen = sen.fit_resample(X_train, y_train)\n",
    "Counter(y_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_sen = LogisticRegression(random_state=42)\n",
    "lr_sen.fit(X_sen, y_sen)\n",
    "\n",
    "# Evaluate model\n",
    "lr_sen_val_pred = lr_sen.predict(X_val)\n",
    "print(classification_report(y_val, lr_sen_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, lr_sen_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, lr_sen_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "tree_sen = DecisionTreeClassifier(random_state=42)\n",
    "tree_sen.fit(X_sen, y_sen)\n",
    "\n",
    "# Evaluate model\n",
    "tree_sen_val_pred = tree_sen.predict(X_val)\n",
    "print(classification_report(y_val, tree_sen_val_pred))\n",
    "print('Accuracy:', accuracy_score(y_val, tree_sen_val_pred))\n",
    "pd.DataFrame(confusion_matrix(y_val, tree_sen_val_pred), index=['0', '1'], columns=['Predicted 0', 'Predicted 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_report(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Using the confusion matrix and classification report, create a custom classification report \n",
    "    with the following values: true positives, false negatives, false positives, true negatives, \n",
    "    and the macro average F1 score, as well as the precision, recall, and F1 score for both classes. \n",
    "    In this case, the positive class is labeled 0 (low risk) and the negative class is labeled 1 \n",
    "    (high risk).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : list-like\n",
    "        True target labels\n",
    "    y_pred : list-like\n",
    "        Predicted target labels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict\n",
    "        Custom classification report with the 11 listed values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    clf_rep = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    # Report values: true 0, false 1, false 0, true 1, F1 for 0, F1 for 1, accuracy\n",
    "    report = confusion_mat.ravel().tolist()\n",
    "    report.extend([clf_rep['0']['precision'], clf_rep['0']['recall'], clf_rep['0']['f1-score'], \n",
    "                   clf_rep['1']['precision'], clf_rep['1']['recall'], clf_rep['1']['f1-score'], \n",
    "                   clf_rep['macro avg']['f1-score']])\n",
    "    \n",
    "    # Add report keys\n",
    "    keys = ['true_pos', 'false_neg', 'false_pos', 'true_neg', \n",
    "            'precision_pos', 'recall_pos', 'f1_pos', \n",
    "            'precision_neg', 'recall_neg', 'f1_neg', 'f1_avg']\n",
    "    report = dict(zip(keys, report))\n",
    "    return report\n",
    "    \n",
    "\n",
    "# Test function\n",
    "clf_report(y_val, lr_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression comparison\n",
    "trials = ['base', 'rand_undersamp', 'centroid_undersamp', 'rand_oversamp', 'smote', 'smoteenn']\n",
    "lr_preds = [lr_val_pred, lr_rus_val_pred, lr_ccu_val_pred, lr_ros_val_pred, lr_smo_val_pred, lr_sen_val_pred]\n",
    "lr_reports = [clf_report(y_val, y_pred) for y_pred in lr_preds]\n",
    "lr_reports_df = pd.DataFrame(lr_reports, index=trials)\n",
    "lr_reports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree comparison\n",
    "tree_preds = [tree_val_pred, tree_rus_val_pred, tree_ccu_val_pred, \n",
    "              tree_ros_val_pred, tree_smo_val_pred, tree_sen_val_pred]\n",
    "tree_reports = [clf_report(y_val, y_pred) for y_pred in tree_preds]\n",
    "tree_reports_df = pd.DataFrame(tree_reports, index=trials)\n",
    "tree_reports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "The decision tree model with random undersampling had the highest precision on high-risk loans and the highest average F1 score, but it missed about 80% of the high-risk loans. On the other hand, the logistic regression models with oversampling were the best at catching high-risk loans, but came with a trade-off of a high number of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled feature coefficients for oversampled logistic regression\n",
    "lr_feats = sorted(zip(np.abs(lr_ros.coef_[0]) / np.abs(lr_ros.coef_[0]).sum(), X_train.columns), reverse=True)\n",
    "lr_feats1 = [feat for feat in lr_feats if feat[0] > 0.01] # feats with greater than 1% relative coefficient\n",
    "print(len(lr_feats1))\n",
    "lr_feats1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled feature coefficients for undersampled decision tree\n",
    "tree_feats = sorted(\n",
    "    zip(np.abs(tree_rus.feature_importances_) / np.abs(tree_rus.feature_importances_).sum(), X_train.columns), \n",
    "    reverse=True)\n",
    "tree_feats1 = [feat for feat in tree_feats if feat[0] > 0.01] # feats with greater than 1% relative coefficient\n",
    "print(len(tree_feats1))\n",
    "tree_feats1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features in both sets\n",
    "feats = np.intersect1d(np.array(lr_feats1)[:, 1], np.array(tree_feats1)[:, 1])\n",
    "print(len(feats))\n",
    "feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minds] *",
   "language": "python",
   "name": "conda-env-minds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
